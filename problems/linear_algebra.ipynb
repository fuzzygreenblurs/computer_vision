{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: To determine the number of linearly independent columns (i.e. the rank) of a matrix A, we can apply a numerical SVD factorization method to the matrix. \n",
    "The number of non-zero values in the sigma (singular values) matrix will represent the rank of the matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of LI columns in A (i.e. its rank):  2\n"
     ]
    }
   ],
   "source": [
    "#### Code\n",
    "\n",
    "A = np.array([\n",
    "    [-1.32, -0.18, 2.13], \n",
    "    [2.64,  -4.68, 4.65], \n",
    "    [1.47,  -4.75, 6.80]\n",
    "])\n",
    "\n",
    "_, S, _ = svd(A)\n",
    "rank = np.count_nonzero(np.round(S))\n",
    "print(\"number of LI columns in A (i.e. its rank): \", rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "#TO_DO: handwritten explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Explanation:\n",
    "We can reproduce the handwritten approach programmatically to determine the parameters for the best fit linear estimate using least squares estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.94  6.52]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.0, 2.5, 6.0, -3.5, 3.0, 8.5])\n",
    "B = np.array([8.5, 3.0, -5.5, 13.0, 0.0, -10.0])\n",
    "A = np.zeros((x.size, 2))\n",
    "for i, elem in enumerate(x):\n",
    "    A[i] = np.array([elem, 1])\n",
    "\n",
    "A_T = np.transpose(A)\n",
    "\n",
    "## note: component C1: (A_transpose * A) ends up having a non-zero determinant, proving it is invertible\n",
    "## this number also matches our handwritten expression above\n",
    "C1 = np.dot(A_T, A)\n",
    "# print(round(np.linalg.det(C1)), \"\\n\")\n",
    "\n",
    "C1_INV = np.linalg.inv(C1)\n",
    "C2 = np.dot(A_T, B)\n",
    "\n",
    "## SOLUTION: this is the parameter q we are solving for in Aq = p_hat \n",
    "# (where p_hat is our closest vector estimate that still falls in A's columnspace)\n",
    "LEAST_SQ_EST_PARAMS = np.round(np.dot(C1_INV, C2), 2)\n",
    "print(LEAST_SQ_EST_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, `w_1`, `w_2` and `w_3` would be a valid set of basis vectors for `R_3`. There are two considerations here:\n",
    "1. Dimensional consistency: Each vector is made of up three components, one for each dimension of R_3\n",
    "2. Linear Independence: If you concatenate the three vectors together, you can quickly see that they are linear independent because they form a 3x3 matrix in upper triangular form. \n",
    "\n",
    "Note: The bottom components of `w_1` and `w_2` are both 0, indicating that there would be no possible linear combination of those two vectors that would yield the required \"k_hat\" component (`1`) in the `w_3` vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly (to problem 3), `t_1`, `t_2` and `t_3` form a valid set of basis vectors for `R_3`. Once again, concatenating these three vectors forms an upper triangular matrix (and therefore one with linear independent column vectors). Additionally, note that this combination of vectors represents a rotation matrix about the \"z\" axis, which would mean that the transformation does not reduce the dimensionality of the output vectorspace (i.e. this matrix would be invertible, which can be further proven by showing the determinant of the matrix to be non-zero. It will be 1 which represents a pure retention of the area of columnspace represented by A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det(A):  1\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [0.707,   0.707,  0], \n",
    "    [-0.707,  0.707,  0], \n",
    "    [0,       0,      1]\n",
    "])\n",
    "\n",
    "print(\"det(A): \", round(np.linalg.det(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors `w_1` through `w_4` do span `R_3` since they each have 3 components, one for each dimension of `R_3`. However, they are not all linearly independent and therefore would not form a basis for `R_3`. Note that `w_1` through `w_3` by themselves would form an upper triangular matrix and would therefore be easily identified as being linearly independent, similar to Problems 3 and 4. `w_4` can be derived as a linear combination of `2(w_1) - w_2 + 3(w_3)` and is therefore redundant. The arithmetic would look like:\n",
    "\n",
    "```python\n",
    "# [\n",
    "#     2(1) -1(1) + 3(0) = 1,\n",
    "#     2(0) -1(1) + 3(1) = 2,\n",
    "#     2(0) -1(0) + 3(1) = 3\n",
    "# ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component vectors: \n",
      " [[0.98733951 0.62206927 0.54653701]] \n",
      " [[0.97136385 0.03514341 0.94217853]] \n",
      " [[0.66264207 0.52940589 0.28833226]] \n",
      "\n",
      "target matrix: \n",
      " [[0.98733951 0.97136385 0.66264207]\n",
      " [0.62206927 0.03514341 0.52940589]\n",
      " [0.54653701 0.94217853 0.28833226]]\n",
      "number of LI columns in A (i.e. its rank):  3\n"
     ]
    }
   ],
   "source": [
    "# approach: I'm using exclusively randomly generated values to show that SVD can always be used to determine rank\n",
    "# (even for linear combinations of floats)\n",
    "\n",
    "v1 = np.random.rand(1, 3)\n",
    "v2 = np.random.rand(1, 3)\n",
    "coeffs = (round(np.random.rand(), 3), round(np.random.rand(), 3))\n",
    "v3 = np.array([(coeffs[0]*a - coeffs[1]*b) for a, b in zip(v1, v2)])\n",
    "\n",
    "\n",
    "print(\"component vectors: \\n\", v1, \"\\n\",  v2, \"\\n\",  v3, \"\\n\")\n",
    "\n",
    "M = np.concatenate([v1.T, v2.T, v3.T], axis=1)\n",
    "print(\"target matrix: \\n\", M)\n",
    "\n",
    "_, S, _ = svd(A)\n",
    "rank = np.count_nonzero(np.round(S))\n",
    "print(\"number of LI columns in A (i.e. its rank): \", rank)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
